{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09c1d65",
   "metadata": {},
   "source": [
    "NaiveBayes Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41cd49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    wordCounts = {}\n",
    "    def __init__(self):\n",
    "        self.wordCounts = {}\n",
    "\n",
    "    def add_to_word_count(self,text,label):\n",
    "        listOfWords = BagOfWords(text)\n",
    "        if self.wordCounts.get(label) == None:\n",
    "            self.wordCounts[label] = listOfWords\n",
    "        else:\n",
    "            for word in listOfWords:\n",
    "                if self.wordCounts[label].get(word) == None:\n",
    "                    self.wordCounts[label][word] = listOfWords[word]\n",
    "                else:\n",
    "                    self.wordCounts[label][word] += listOfWords[word]\n",
    "        return\n",
    "    \n",
    "    def add_word_threshold(self, threshold):\n",
    "        items_below_threshold = []\n",
    "        for label in self.wordCounts.keys():\n",
    "            for word in self.wordCounts[label]:\n",
    "                if self.wordCounts[label][word] <= threshold:\n",
    "                     items_below_threshold.append([label, word])\n",
    "        \n",
    "                     \n",
    "        for item in items_below_threshold:    \n",
    "            del self.wordCounts[item[0]][item[1]]\n",
    "\n",
    "    def predict_text(self,text):\n",
    "        wordarr = BagOfWords(text)\n",
    "        labels = list(self.wordCounts.keys())\n",
    "        probabilities = {}\n",
    "        \n",
    "        for label in labels:\n",
    "            probabilities[label] = 1\n",
    "            \n",
    "        #find highest probility\n",
    "        for word in wordarr:\n",
    "            for label in labels:\n",
    "                prob = self.calculate_probability(word,label)\n",
    "                if prob > 0:\n",
    "                    probabilities[label] *= prob\n",
    "        \n",
    "        highest = probabilities[labels[0]]\n",
    "        highestlabel = labels[0]\n",
    "        for label in labels:\n",
    "            #print(probabilities[label])\n",
    "            if probabilities[label] > highest:\n",
    "                #print(\"prev highest\", highestlabel,'new:',label)\n",
    "                highest = probabilities[label]\n",
    "                highestlabel = label\n",
    "     \n",
    "        return highestlabel\n",
    "        \n",
    "    \n",
    "    def calculate_probability(self,word,lab):\n",
    "        labels = self.wordCounts.keys()\n",
    "        total = 0\n",
    "        labcount = self.wordCounts[lab].get(word,0)\n",
    "        for label in labels:\n",
    "            total += self.wordCounts[label].get(word,0)\n",
    "        #print(word,\" \",lab,\":\",labcount,total,labcount/total )\n",
    "        if (labcount == 0 or total == 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return labcount/total\n",
    "\n",
    "def BagOfWords(wordarr):\n",
    "    wordCount = {}\n",
    "    \n",
    "    for word in wordarr:\n",
    "            if wordCount.get(word) != None:\n",
    "                wordCount[word] += 1\n",
    "            else:\n",
    "                wordCount[word] = 1\n",
    "    return wordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2dbd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cd8ef64",
   "metadata": {},
   "source": [
    "Data is a set of articles that are labeled either objective or subjective\n",
    "Data: https://archive.ics.uci.edu/ml/machine-learning-databases/00450/\n",
    "Data/\n",
    "    Features.csv\n",
    "    Text0001.txt\n",
    "    Text0001.txt\n",
    "    ............\n",
    "    Text1000.txt\n",
    "    \n",
    "Features.csv: Headers for the data\n",
    "Text0001,...,objective,....\n",
    "Text0700,...,subjective,....\n",
    "\n",
    "TextXXXX.txt: Article full of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f264b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TextID,URL,Label,totalWordsCount,semanticobjscore,semanticsubjscore,CC,CD,DT,EX,FW,INs,JJ,JJR,JJS,LS,MD,NN,NNP,NNPS,NNS,PDT,POS,PRP,PRP$,RB,RBR,RBS,RP,SYM,TOs,UH,VB,VBD,VBG,VBN,VBP,VBZ,WDT,WP,WP$,WRB,baseform,Quotes,questionmarks,exclamationmarks,fullstops,commas,semicolon,colon,ellipsis,pronouns1st,pronouns2nd,pronouns3rd,compsupadjadv,past,imperative,present3rd,present1st2nd,sentence1st,sentencelast,txtcomplexity\\n', 'Text0001,http://msn.foxsports.com/foxsoccer/mexico/story/mexican-review-jan-19-toluca-secures-first-victory-beats-leon-011913,objective,109,0,1,7,9,0,5,8,6,0,0,0,0,29,0,0,12,0,0,1,2,2,0,0,2,0,3,0,0,11,0,2,0,0,0,1,0,1,0,2,0,0,0,4,2,0,0,0,0,0,3,0,11,0,0,0,0,1,18\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"Data/features.csv\") as file:\n",
    "    head = [next(file) for x in range(2)]\n",
    "print(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff5819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalists in the Apertura play-offs, Toluca had drawn their first two Clausura games but got off to a good start when Edgar Benitez put them ahead in the 16th minute.\n",
      "Matias Britos levelled 20 minutes later but Lucas Silva netted 14 minutes from the end to ensure the visitors took all three points.\n",
      "  \tFranco Arizala scored 13 minutes from time to ensure Jaguares claimed their first point with a 1-1 draw against Monterrey, who had opened the scoring through Aldo De Nigris (14).\n",
      " Hosts Jaguares also had Jorge Rodriguez sent off in the closing moments.\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Text0001.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dc207",
   "metadata": {},
   "source": [
    "Time to parse and celanup the data. Since the words and labels are not in the same documet, this becomes slightly more complex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba28c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def ParseFeatures(file_path):\n",
    "    features = {}\n",
    "    with open(file_path) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            features[row[0]] = Article(0 if row[2] == \"objective\" else 1)\n",
    "    return features\n",
    "\n",
    "def GetWordsFromArticle(path):\n",
    "    with open(path, encoding=\"ISO-8859-1\") as f:\n",
    "        words = []\n",
    "        for row in f.read().split():\n",
    "            # Remove all special characters\n",
    "            word = ''.join(e for e in row if e.isalnum())\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, label):\n",
    "         self.label = label\n",
    "         self.words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20da77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f642fdc0",
   "metadata": {},
   "source": [
    "Time to start using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed8f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "data = ParseFeatures(\"Data/features.csv\")\n",
    "print(data[\"Text0001\"].label, end=' ')\n",
    "print(data[\"Text0001\"].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "420022e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Finalists', 'in', 'the', 'Apertura', 'playoffs', 'Toluca', 'had', 'drawn', 'their', 'first', 'two', 'Clausura', 'games', 'but', 'got', 'off', 'to', 'a', 'good', 'start', 'when', 'Edgar', 'Benitez', 'put', 'them', 'ahead', 'in', 'the', '16th', 'minute', 'Matias', 'Britos', 'levelled', '20', 'minutes', 'later', 'but', 'Lucas', 'Silva', 'netted', '14', 'minutes', 'from', 'the', 'end', 'to', 'ensure', 'the', 'visitors', 'took', 'all', 'three', 'points', 'Franco', 'Arizala', 'scored', '13', 'minutes', 'from', 'time', 'to', 'ensure', 'Jaguares', 'claimed', 'their', 'first', 'point', 'with', 'a', '11', 'draw', 'against', 'Monterrey', 'who', 'had', 'opened', 'the', 'scoring', 'through', 'Aldo', 'De', 'Nigris', '14', 'Hosts', 'Jaguares', 'also', 'had', 'Jorge', 'Rodriguez', 'sent', 'off', 'in', 'the', 'closing', 'moments']\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    data[key].words = GetWordsFromArticle(\"Data/\" + key + \".txt\")\n",
    "print(data[\"Text0001\"].label,end=' ')\n",
    "print(data[\"Text0001\"].words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539edbf",
   "metadata": {},
   "source": [
    "\n",
    "Setup our training and validation. First we need to create a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2885b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class CrossValidationManager:\n",
    "    k = 0\n",
    "    data_length = 0\n",
    "    data_indexes = {}\n",
    "    current_index = -1\n",
    "\n",
    "    def __init__(self, k_times, data, seed = 0):\n",
    "        self.k = k_times\n",
    "        self.data = data\n",
    "        if (seed > 0):\n",
    "            random.Random(seed).shuffle(self.data)\n",
    "        else:\n",
    "            random.shuffle(self.data)\n",
    "        self._get_indexes()\n",
    "    \n",
    "    def _get_indexes(self):\n",
    "        length = int(len(self.data) / self.k)\n",
    "        remainder = len(self.data) % self.k\n",
    "\n",
    "        if remainder > 0:\n",
    "            length += 1\n",
    "        else:\n",
    "            remainder = -1\n",
    "\n",
    "        for index in range(self.k):\n",
    "            if remainder > 0:\n",
    "                remainder -= 1\n",
    "            elif remainder == 0:\n",
    "                length -= 1\n",
    "                remainder = -1\n",
    "\n",
    "            if index == 0:\n",
    "                self.data_indexes[index] = [0,length]\n",
    "            else:\n",
    "                previous_end_index = self.data_indexes[index-1][1]\n",
    "                self.data_indexes[index] = [previous_end_index, previous_end_index + length]\n",
    "    \n",
    "    def data_available(self):\n",
    "        self.current_index += 1\n",
    "        if self.current_index == self.k:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def get_training_data(self):\n",
    "        data = []\n",
    "        for i in range(self.k):\n",
    "            if i == self.current_index:\n",
    "                continue\n",
    "            s = self.data_indexes[i][0]\n",
    "            e = self.data_indexes[i][1]\n",
    "            data += self.data[s:e]\n",
    "        return data\n",
    "    \n",
    "    def get_validation_data(self):\n",
    "        s = self.data_indexes[self.current_index][0]\n",
    "        e = self.data_indexes[self.current_index][1]\n",
    "        return self.data[s:e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eae57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "K_FOLD_COUNT = 5\n",
    "# Changing the seed will shuffle the data differently but consistently between runs\n",
    "# 0 will shuffle differently every run of the program\n",
    "SEED = 12\n",
    "\n",
    "dataManager = CrossValidationManager(K_FOLD_COUNT, list(data), seed=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ea5f7",
   "metadata": {},
   "source": [
    "We have all of our data setup. Send it to our alg and make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27ef361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0 Correct: 142/200\n",
      "60.5 Correct: 121/200\n",
      "79.5 Correct: 159/200\n",
      "82.0 Correct: 164/200\n",
      "76.5 Correct: 153/200\n"
     ]
    }
   ],
   "source": [
    "while dataManager.data_available():\n",
    "    n = NaiveBayes()\n",
    "    trainData = dataManager.get_training_data()\n",
    "    valData = dataManager.get_validation_data()\n",
    "\n",
    "    # Train\n",
    "    for article_name in trainData:\n",
    "        n.add_to_word_count(GetWordsFromArticle(\"Data/\" + article_name + \".txt\"), data[article_name].label)\n",
    "    \n",
    "    #n.add_word_threshold(2)\n",
    "\n",
    "    #Test\n",
    "    validationData = {}\n",
    "    for article_name in valData:\n",
    "        validationData[article_name] = [GetWordsFromArticle(\"Data/\" + article_name + \".txt\"), data[article_name].label]\n",
    "\n",
    "    correct = 0\n",
    "    for words in validationData.items():\n",
    "        prediction = n.predict_text(words[1][0])\n",
    "        \n",
    "        if prediction == words[1][1]:\n",
    "            correct += 1\n",
    "    print((correct / len(validationData)) * 100, end='')\n",
    "    print(\" Correct: \" + str(correct) + \"/\" + str(len(validationData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4151e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
